
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Diskirminasi menggunakan K-means &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'kategorinw';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Selamat datang Di catatan Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="datamining.html">Data Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="UTSPendataE.html"><strong>Mengistall Pandas terlebih dahulu</strong></a></li>



<li class="toctree-l1"><a class="reference internal" href="PraUASnw.html"><strong>Memprediksi Kelangsungan hidup seorang Pasien Pengidap Penyakit Sirosis</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="UAS.html"><strong>Prediksi Risiko Kesehatan Ibu Hamil</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fkategorinw.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/kategorinw.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Diskirminasi menggunakan K-means</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Diskirminasi menggunakan K-means</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengertian-diskritisasi-discretization"><strong>Pengertian Diskritisasi (Discretization)</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-1"><strong>Klasifikasi 1</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengumpulkan-data-iris"><strong>Mengumpulkan data Iris</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-naive-bayes"><strong>Klasifikasi menggunakan naive bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-decisiontree"><strong>Klasifikasi menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-prediksi-keduanya"><strong>Hasil Prediksi keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-2"><strong>Klasifikasi 2</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Mengumpulkan data Iris</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dan-cluster-data-menjadi-4-kelas"><strong>Diskritisasi data dan Cluster data menjadi 4 kelas</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>Klasifikasi menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>Klasifikasi Menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akurasi-keduanya"><strong>Hasil Akurasi Keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-3"><strong>Klasifikasi 3</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dengan-equal-width-binning"><strong>Diskritisasi Data dengan Equal Width-Binning</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-equal-width-binning-untuk-data-iris-sebagai-berikut"><strong>Langkah-langkah Equal Width-Binning untuk data Iris Sebagai berikut:</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Klasifikasi Menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Klasifikasi Menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Hasil Akurasi Keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-4"><strong>Klasifikasi 4</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-dengan-equal-frequency"><strong>Klasifikasi data dengan Equal Frequency</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-equal-frequency-untuk-data-iris-sebagai-berikut"><strong>Langkah-langkah Equal Frequency untuk data Iris sebagai berikut:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Klasifikasi Menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifisikas-dengan-decisiontree"><strong>Klasifisikas dengan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Hasil Akurasi Keduanya</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-perbandingan-akhir">✅<strong>Hasil Perbandingan Akhir</strong></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="diskirminasi-menggunakan-k-means">
<h1><strong>Diskirminasi menggunakan K-means</strong><a class="headerlink" href="#diskirminasi-menggunakan-k-means" title="Link to this heading">#</a></h1>
<section id="pengertian-diskritisasi-discretization">
<h2><strong>Pengertian Diskritisasi (Discretization)</strong><a class="headerlink" href="#pengertian-diskritisasi-discretization" title="Link to this heading">#</a></h2>
<p>Diskritisasi
merupakan proses kuantisasi sifat-sifat kontinu.
Kuantisasi diartikan sebagai proses
pengelompokan sifat-sifat kontinu pada selangselang tertentu (step size). Kegunaan diskritisasi
adalah untuk mereduksi dan menyederhanakan
data, sehingga didapatkan data diskrit yang lebih
mudah dipahami, digunakan, dan dijelaskan.
Oleh karena itu, hasil pembelajaran dengan
bentuk diskrit dipandang Dougherty (1995)
sebagai hasil yang cepat dan akurat
dibandingkan hasil dari bentuk kontinu (Liu,
Hussain, Tan, &amp; Dash, 2012)
Proses ini bertujuan untuk mereduksi dan menyederhanakan data sehingga menjadi lebih mudah dipahami, digunakan, dan dijelaskan
proses di mana kita dapat mengubah variabel kontinu, model atau fungsi menjadi bentuk diskrit. kita dapat melakukan ini dengan membuat satu set interval yang berdekatan yang melintasi rentang variabel / model / fungsi yang diinginkan.</p>
<p>Diskritisasi memiliki kegunaan penting dalam berbagai metode lain, terutama dalam metode numerik untuk menyelesaikan masalah yang awalnya berbentuk kontinu menjadi bentuk diskrit yang dapat dihitung secara numerik salah satunya Dalam data mining dan pembelajaran mesin, diskritisasi digunakan untuk mengubah data numerik kontinu menjadi data kategorik, yang dapat meningkatkan akurasi klasifikasi dan mempercepat proses mining data, misalnya dalam metode decision tree dengan teknik diskritisasi seperti equal-width interval atau clustering-based discretization.</p>
<p>Dari beberapa metode pengolahan data baik tahap understanding, proseccing atau yang lain, deskritisasi sangat perlu digunakan dalam tahapan tersebut. contoh paada metode K-Means,Diskritisasi dengan K-Means dianggap lebih baik dibandingkan metode diskritisasi interval sama (equal interval) karena mampu menangani batas nilai dengan lebih baik dan menghasilkan distribusi cluster yang lebih seimbang. Namun, hasil diskritisasi sangat bergantung pada nilai k dan inisialisasi centroid awal, serta dapat terpengaruh oleh outlier data. Kelemahan lain adalah K-Means mengasumsikan cluster berbentuk bulat dan ukuran serta densitas cluster seragam, sehingga kurang cocok untuk data dengan cluster yang berbeda bentuk atau kepadatan.</p>
<p>Secara umum, diskritisasi dengan K-Means banyak digunakan sebagai preprocessing untuk meningkatkan akurasi algoritma klasifikasi seperti Naïve Bayes dan decision tree dengan mengubah atribut numerik menjadi kategorikal yang lebih mudah diolah.</p>
<p>Berikut ini diberikan sebuah contoh data iris, Membuat klasifikasi menggunakan data yang kategori dengan data belum kategori</p>
</section>
</section>
<section id="klasifikasi-1">
<h1><strong>Klasifikasi 1</strong><a class="headerlink" href="#klasifikasi-1" title="Link to this heading">#</a></h1>
<section id="mengumpulkan-data-iris">
<h2><strong>Mengumpulkan data Iris</strong><a class="headerlink" href="#mengumpulkan-data-iris" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="c1"># Fungsi ambil data Iris dan atur ulang kolom</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_iris_data</span><span class="p">():</span>
    <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="o">.</span><span class="n">from_codes</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># ID dimulai dari 1</span>

    <span class="c1"># Susun ulang kolom: id, class, lalu fitur</span>
    <span class="n">columns_order</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns_order</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># Ambil data</span>
<span class="n">df_iris</span> <span class="o">=</span> <span class="n">get_iris_data</span><span class="p">()</span>

<span class="c1"># Muat data Iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Semua fitur: shape (150, 4)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>

<span class="c1"># Cetak tanpa indeks</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_iris</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id      class  sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
  1     setosa                5.1               3.5                1.4               0.2
  2     setosa                4.9               3.0                1.4               0.2
  3     setosa                4.7               3.2                1.3               0.2
  4     setosa                4.6               3.1                1.5               0.2
  5     setosa                5.0               3.6                1.4               0.2
  6     setosa                5.4               3.9                1.7               0.4
  7     setosa                4.6               3.4                1.4               0.3
  8     setosa                5.0               3.4                1.5               0.2
  9     setosa                4.4               2.9                1.4               0.2
 10     setosa                4.9               3.1                1.5               0.1
 11     setosa                5.4               3.7                1.5               0.2
 12     setosa                4.8               3.4                1.6               0.2
 13     setosa                4.8               3.0                1.4               0.1
 14     setosa                4.3               3.0                1.1               0.1
 15     setosa                5.8               4.0                1.2               0.2
 16     setosa                5.7               4.4                1.5               0.4
 17     setosa                5.4               3.9                1.3               0.4
 18     setosa                5.1               3.5                1.4               0.3
 19     setosa                5.7               3.8                1.7               0.3
 20     setosa                5.1               3.8                1.5               0.3
 21     setosa                5.4               3.4                1.7               0.2
 22     setosa                5.1               3.7                1.5               0.4
 23     setosa                4.6               3.6                1.0               0.2
 24     setosa                5.1               3.3                1.7               0.5
 25     setosa                4.8               3.4                1.9               0.2
 26     setosa                5.0               3.0                1.6               0.2
 27     setosa                5.0               3.4                1.6               0.4
 28     setosa                5.2               3.5                1.5               0.2
 29     setosa                5.2               3.4                1.4               0.2
 30     setosa                4.7               3.2                1.6               0.2
 31     setosa                4.8               3.1                1.6               0.2
 32     setosa                5.4               3.4                1.5               0.4
 33     setosa                5.2               4.1                1.5               0.1
 34     setosa                5.5               4.2                1.4               0.2
 35     setosa                4.9               3.1                1.5               0.2
 36     setosa                5.0               3.2                1.2               0.2
 37     setosa                5.5               3.5                1.3               0.2
 38     setosa                4.9               3.6                1.4               0.1
 39     setosa                4.4               3.0                1.3               0.2
 40     setosa                5.1               3.4                1.5               0.2
 41     setosa                5.0               3.5                1.3               0.3
 42     setosa                4.5               2.3                1.3               0.3
 43     setosa                4.4               3.2                1.3               0.2
 44     setosa                5.0               3.5                1.6               0.6
 45     setosa                5.1               3.8                1.9               0.4
 46     setosa                4.8               3.0                1.4               0.3
 47     setosa                5.1               3.8                1.6               0.2
 48     setosa                4.6               3.2                1.4               0.2
 49     setosa                5.3               3.7                1.5               0.2
 50     setosa                5.0               3.3                1.4               0.2
 51 versicolor                7.0               3.2                4.7               1.4
 52 versicolor                6.4               3.2                4.5               1.5
 53 versicolor                6.9               3.1                4.9               1.5
 54 versicolor                5.5               2.3                4.0               1.3
 55 versicolor                6.5               2.8                4.6               1.5
 56 versicolor                5.7               2.8                4.5               1.3
 57 versicolor                6.3               3.3                4.7               1.6
 58 versicolor                4.9               2.4                3.3               1.0
 59 versicolor                6.6               2.9                4.6               1.3
 60 versicolor                5.2               2.7                3.9               1.4
 61 versicolor                5.0               2.0                3.5               1.0
 62 versicolor                5.9               3.0                4.2               1.5
 63 versicolor                6.0               2.2                4.0               1.0
 64 versicolor                6.1               2.9                4.7               1.4
 65 versicolor                5.6               2.9                3.6               1.3
 66 versicolor                6.7               3.1                4.4               1.4
 67 versicolor                5.6               3.0                4.5               1.5
 68 versicolor                5.8               2.7                4.1               1.0
 69 versicolor                6.2               2.2                4.5               1.5
 70 versicolor                5.6               2.5                3.9               1.1
 71 versicolor                5.9               3.2                4.8               1.8
 72 versicolor                6.1               2.8                4.0               1.3
 73 versicolor                6.3               2.5                4.9               1.5
 74 versicolor                6.1               2.8                4.7               1.2
 75 versicolor                6.4               2.9                4.3               1.3
 76 versicolor                6.6               3.0                4.4               1.4
 77 versicolor                6.8               2.8                4.8               1.4
 78 versicolor                6.7               3.0                5.0               1.7
 79 versicolor                6.0               2.9                4.5               1.5
 80 versicolor                5.7               2.6                3.5               1.0
 81 versicolor                5.5               2.4                3.8               1.1
 82 versicolor                5.5               2.4                3.7               1.0
 83 versicolor                5.8               2.7                3.9               1.2
 84 versicolor                6.0               2.7                5.1               1.6
 85 versicolor                5.4               3.0                4.5               1.5
 86 versicolor                6.0               3.4                4.5               1.6
 87 versicolor                6.7               3.1                4.7               1.5
 88 versicolor                6.3               2.3                4.4               1.3
 89 versicolor                5.6               3.0                4.1               1.3
 90 versicolor                5.5               2.5                4.0               1.3
 91 versicolor                5.5               2.6                4.4               1.2
 92 versicolor                6.1               3.0                4.6               1.4
 93 versicolor                5.8               2.6                4.0               1.2
 94 versicolor                5.0               2.3                3.3               1.0
 95 versicolor                5.6               2.7                4.2               1.3
 96 versicolor                5.7               3.0                4.2               1.2
 97 versicolor                5.7               2.9                4.2               1.3
 98 versicolor                6.2               2.9                4.3               1.3
 99 versicolor                5.1               2.5                3.0               1.1
100 versicolor                5.7               2.8                4.1               1.3
101  virginica                6.3               3.3                6.0               2.5
102  virginica                5.8               2.7                5.1               1.9
103  virginica                7.1               3.0                5.9               2.1
104  virginica                6.3               2.9                5.6               1.8
105  virginica                6.5               3.0                5.8               2.2
106  virginica                7.6               3.0                6.6               2.1
107  virginica                4.9               2.5                4.5               1.7
108  virginica                7.3               2.9                6.3               1.8
109  virginica                6.7               2.5                5.8               1.8
110  virginica                7.2               3.6                6.1               2.5
111  virginica                6.5               3.2                5.1               2.0
112  virginica                6.4               2.7                5.3               1.9
113  virginica                6.8               3.0                5.5               2.1
114  virginica                5.7               2.5                5.0               2.0
115  virginica                5.8               2.8                5.1               2.4
116  virginica                6.4               3.2                5.3               2.3
117  virginica                6.5               3.0                5.5               1.8
118  virginica                7.7               3.8                6.7               2.2
119  virginica                7.7               2.6                6.9               2.3
120  virginica                6.0               2.2                5.0               1.5
121  virginica                6.9               3.2                5.7               2.3
122  virginica                5.6               2.8                4.9               2.0
123  virginica                7.7               2.8                6.7               2.0
124  virginica                6.3               2.7                4.9               1.8
125  virginica                6.7               3.3                5.7               2.1
126  virginica                7.2               3.2                6.0               1.8
127  virginica                6.2               2.8                4.8               1.8
128  virginica                6.1               3.0                4.9               1.8
129  virginica                6.4               2.8                5.6               2.1
130  virginica                7.2               3.0                5.8               1.6
131  virginica                7.4               2.8                6.1               1.9
132  virginica                7.9               3.8                6.4               2.0
133  virginica                6.4               2.8                5.6               2.2
134  virginica                6.3               2.8                5.1               1.5
135  virginica                6.1               2.6                5.6               1.4
136  virginica                7.7               3.0                6.1               2.3
137  virginica                6.3               3.4                5.6               2.4
138  virginica                6.4               3.1                5.5               1.8
139  virginica                6.0               3.0                4.8               1.8
140  virginica                6.9               3.1                5.4               2.1
141  virginica                6.7               3.1                5.6               2.4
142  virginica                6.9               3.1                5.1               2.3
143  virginica                5.8               2.7                5.1               1.9
144  virginica                6.8               3.2                5.9               2.3
145  virginica                6.7               3.3                5.7               2.5
146  virginica                6.7               3.0                5.2               2.3
147  virginica                6.3               2.5                5.0               1.9
148  virginica                6.5               3.0                5.2               2.0
149  virginica                6.2               3.4                5.4               2.3
150  virginica                5.9               3.0                5.1               1.8
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-menggunakan-naive-bayes">
<h2><strong>Klasifikasi menggunakan naive bayes</strong><a class="headerlink" href="#klasifikasi-menggunakan-naive-bayes" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Setelah data iris dikumpulakan klasifikasikan dengan metode naive bayes dan PCA.Tujuan dari penggunaan metode kombinasi Principal Component Analysis (PCA) dan Naive Bayes pada data Iris adalah untuk mereduksi dimensi fitur dari empat (sepal length, sepal width, petal length, dan petal width) menjadi dua dimensi utama (PC1 dan PC2), sehingga data dapat divisualisasikan secara 2D. PCA membantu menyederhanakan data tanpa kehilangan terlalu banyak informasi penting, sementara Naive Bayes digunakan untuk melakukan klasifikasi berdasarkan distribusi probabilitas dari data. Dengan menampilkan hasil klasifikasi dalam bentuk plot dua dimensi, kita dapat memahami sejauh mana model mampu memisahkan kelas-kelas bunga berdasarkan dua komponen utama tersebut.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Hasil visualisasi menunjukkan bahwa setosa sangat mudah dibedakan dari kelas lain karena titik-titiknya berkelompok jelas di area tertentu, baik berdasarkan label asli maupun prediksi model. Namun, versicolor dan virginica sering kali tampak tumpang tindih di ruang dua dimensi, yang menyebabkan beberapa kesalahan klasifikasi oleh model Naive Bayes. Meski demikian, secara umum prediksi model cukup akurat karena sebagian besar titik memiliki warna (prediksi) dan bentuk (label asli) yang sama. Hal ini menunjukkan bahwa PCA cukup efektif dalam merangkum informasi penting dari data dan Naive Bayes mampu memanfaatkan informasi tersebut untuk klasifikasi, meskipun ada keterbatasan ketika kelas-kelas memiliki distribusi yang saling tumpang tindih. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Siapkan fitur dan label</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_iris</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span>  <span class="c1"># fitur numerik asli</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_iris</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>        <span class="c1"># label kelas (setosa, versicolor, virginica)</span>

<span class="c1"># Bagi data menjadi data latih dan data uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Buat dan latih model Gaussian Naive Bayes</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil klasifikasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix:
[[10  0  0]
 [ 0  9  0]
 [ 0  0 11]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       1.00      1.00      1.00         9
   virginica       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30

Akurasi: 1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-menggunakan-decisiontree">
<h2><strong>Klasifikasi menggunakan DecisionTree</strong><a class="headerlink" href="#klasifikasi-menggunakan-decisiontree" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Tujuan dari penerapan Decision Tree pada dataset Iris adalah untuk membangun model klasifikasi yang dapat menjelaskan secara eksplisit proses pengambilan keputusan berdasarkan fitur-fitur sepal dan petal. Decision Tree bekerja dengan mempartisi data ke dalam cabang-cabang berdasarkan nilai ambang batas fitur yang memaksimalkan pemisahan antar kelas. Tidak seperti Naive Bayes yang mengasumsikan distribusi probabilitas, Decision Tree memberikan pendekatan yang sangat interpretatif, memungkinkan kita untuk melihat logika keputusan dalam bentuk diagram pohon. Visualisasi ini sangat berguna untuk memahami fitur mana yang paling berpengaruh dalam membedakan kelas bunga.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Hasil evaluasi menunjukkan bahwa model Decision Tree menghasilkan akurasi tinggi, biasanya setara atau sedikit lebih baik dibanding Naive Bayes, tergantung pada pemisahan data training dan testing. Confusion matrix dan classification report memperlihatkan bahwa klasifikasi untuk setosa sangat akurat, sementara beberapa kesalahan klasifikasi mungkin terjadi pada kelas versicolor dan virginica yang memiliki kemiripan karakteristik. Visualisasi pohon keputusan menunjukkan secara langsung urutan fitur yang digunakan untuk membelah data serta nilai-nilai threshold yang digunakan, misalnya petal length (cm) sering muncul di level atas karena merupakan fitur yang sangat menentukan. Model ini sangat bermanfaat dalam konteks interpretabilitas dan pengambilan keputusan berbasis aturan eksplisit. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inisialisasi dan latih Model</span>
<span class="n">model_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi &amp; Evaluasi</span>
<span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">model_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix (Decision Tree):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report (Decision Tree):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Accuracy Score (Decision Tree):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>

<span class="c1"># Visualisasi Pohon Keputusan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">model_dt</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi Pohon Keputusan (Decision Tree)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix (Decision Tree):
[[10  0  0]
 [ 0  9  0]
 [ 0  0 11]]

Classification Report (Decision Tree):
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       1.00      1.00      1.00         9
   virginica       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30


Accuracy Score (Decision Tree): 1.0
</pre></div>
</div>
<img alt="_images/f349be339fcf5d310a3ffa17df3a975650a565e829205530f282e43cdd5c253e.png" src="_images/f349be339fcf5d310a3ffa17df3a975650a565e829205530f282e43cdd5c253e.png" />
</div>
</div>
</section>
<section id="hasil-prediksi-keduanya">
<h2><strong>Hasil Prediksi keduanya</strong><a class="headerlink" href="#hasil-prediksi-keduanya" title="Link to this heading">#</a></h2>
<p>Hasil perbandingan klasifikasi antara Naive Bayes dan Decision Tree pada dataset Iris menunjukkan bahwa kedua model memiliki tingkat akurasi yang sangat tinggi dan hampir setara, naive bayes 0,91 dan DecisionTree 0,93. Naive Bayes bekerja baik karena asumsi distribusi normal pada fitur-fitur numerik dataset Iris cukup terpenuhi, sedangkan Decision Tree mampu menghasilkan keputusan yang akurat dengan mempartisi data secara eksplisit berdasarkan nilai-nilai fitur tanpa asumsi distribusi tertentu. Meskipun hasilnya hampir serupa, Decision Tree memiliki keunggulan dalam interpretabilitas melalui visualisasi pohon keputusan, sementara Naive Bayes lebih sederhana dan efisien dalam komputasi. Dengan demikian, pemilihan model dapat disesuaikan berdasarkan kebutuhan antara efisiensi atau interpretasi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Actual&quot;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>
    <span class="s2">&quot;NaiveBayes_Pred&quot;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
    <span class="s2">&quot;DecisionTree_Pred&quot;</span><span class="p">:</span> <span class="n">y_pred_dt</span>
<span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df_result</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Hitung akurasi masing-masing model</span>
<span class="n">accuracy_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>


<span class="c1"># === Cetak akurasi kedua model ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Perbandingan Akurasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Naive Bayes     : </span><span class="si">{</span><span class="n">accuracy_nb</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Decision Tree   : </span><span class="si">{</span><span class="n">accuracy_dt</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Buat DataFrame untuk visualisasi</span>
<span class="n">accuracy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Model&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">accuracy_nb</span><span class="p">,</span> <span class="n">accuracy_dt</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">:</span> <span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">:</span> <span class="s1">&#39;lightgreen&#39;</span><span class="p">}</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">accuracy_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi Model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         Actual NaiveBayes_Pred DecisionTree_Pred
73   versicolor      versicolor        versicolor
18       setosa          setosa            setosa
118   virginica       virginica         virginica
78   versicolor      versicolor        versicolor
76   versicolor      versicolor        versicolor

=== Perbandingan Akurasi ===
Akurasi Naive Bayes     : 1.0000
Akurasi Decision Tree   : 1.0000
</pre></div>
</div>
<img alt="_images/95dbfa2979506b1dbab82683e3a395e27a175b475ff0db36a125a76ceb47e7fe.png" src="_images/95dbfa2979506b1dbab82683e3a395e27a175b475ff0db36a125a76ceb47e7fe.png" />
</div>
</div>
</section>
</section>
<section id="klasifikasi-2">
<h1><strong>Klasifikasi 2</strong><a class="headerlink" href="#klasifikasi-2" title="Link to this heading">#</a></h1>
<section id="id1">
<h2><strong>Mengumpulkan data Iris</strong><a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fungsi ambil data Iris dan atur ulang kolom</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_iris_data</span><span class="p">():</span>
    <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="o">.</span><span class="n">from_codes</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># ID dimulai dari 1</span>

    <span class="c1"># Susun ulang kolom: id, class, lalu fitur</span>
    <span class="n">columns_order</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns_order</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># Ambil data</span>
<span class="n">df_iris</span> <span class="o">=</span> <span class="n">get_iris_data</span><span class="p">()</span>

<span class="c1"># Muat data Iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Semua fitur: shape (150, 4)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>

<span class="c1"># Cetak tanpa indeks</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_iris</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id      class  sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
  1     setosa                5.1               3.5                1.4               0.2
  2     setosa                4.9               3.0                1.4               0.2
  3     setosa                4.7               3.2                1.3               0.2
  4     setosa                4.6               3.1                1.5               0.2
  5     setosa                5.0               3.6                1.4               0.2
  6     setosa                5.4               3.9                1.7               0.4
  7     setosa                4.6               3.4                1.4               0.3
  8     setosa                5.0               3.4                1.5               0.2
  9     setosa                4.4               2.9                1.4               0.2
 10     setosa                4.9               3.1                1.5               0.1
 11     setosa                5.4               3.7                1.5               0.2
 12     setosa                4.8               3.4                1.6               0.2
 13     setosa                4.8               3.0                1.4               0.1
 14     setosa                4.3               3.0                1.1               0.1
 15     setosa                5.8               4.0                1.2               0.2
 16     setosa                5.7               4.4                1.5               0.4
 17     setosa                5.4               3.9                1.3               0.4
 18     setosa                5.1               3.5                1.4               0.3
 19     setosa                5.7               3.8                1.7               0.3
 20     setosa                5.1               3.8                1.5               0.3
 21     setosa                5.4               3.4                1.7               0.2
 22     setosa                5.1               3.7                1.5               0.4
 23     setosa                4.6               3.6                1.0               0.2
 24     setosa                5.1               3.3                1.7               0.5
 25     setosa                4.8               3.4                1.9               0.2
 26     setosa                5.0               3.0                1.6               0.2
 27     setosa                5.0               3.4                1.6               0.4
 28     setosa                5.2               3.5                1.5               0.2
 29     setosa                5.2               3.4                1.4               0.2
 30     setosa                4.7               3.2                1.6               0.2
 31     setosa                4.8               3.1                1.6               0.2
 32     setosa                5.4               3.4                1.5               0.4
 33     setosa                5.2               4.1                1.5               0.1
 34     setosa                5.5               4.2                1.4               0.2
 35     setosa                4.9               3.1                1.5               0.2
 36     setosa                5.0               3.2                1.2               0.2
 37     setosa                5.5               3.5                1.3               0.2
 38     setosa                4.9               3.6                1.4               0.1
 39     setosa                4.4               3.0                1.3               0.2
 40     setosa                5.1               3.4                1.5               0.2
 41     setosa                5.0               3.5                1.3               0.3
 42     setosa                4.5               2.3                1.3               0.3
 43     setosa                4.4               3.2                1.3               0.2
 44     setosa                5.0               3.5                1.6               0.6
 45     setosa                5.1               3.8                1.9               0.4
 46     setosa                4.8               3.0                1.4               0.3
 47     setosa                5.1               3.8                1.6               0.2
 48     setosa                4.6               3.2                1.4               0.2
 49     setosa                5.3               3.7                1.5               0.2
 50     setosa                5.0               3.3                1.4               0.2
 51 versicolor                7.0               3.2                4.7               1.4
 52 versicolor                6.4               3.2                4.5               1.5
 53 versicolor                6.9               3.1                4.9               1.5
 54 versicolor                5.5               2.3                4.0               1.3
 55 versicolor                6.5               2.8                4.6               1.5
 56 versicolor                5.7               2.8                4.5               1.3
 57 versicolor                6.3               3.3                4.7               1.6
 58 versicolor                4.9               2.4                3.3               1.0
 59 versicolor                6.6               2.9                4.6               1.3
 60 versicolor                5.2               2.7                3.9               1.4
 61 versicolor                5.0               2.0                3.5               1.0
 62 versicolor                5.9               3.0                4.2               1.5
 63 versicolor                6.0               2.2                4.0               1.0
 64 versicolor                6.1               2.9                4.7               1.4
 65 versicolor                5.6               2.9                3.6               1.3
 66 versicolor                6.7               3.1                4.4               1.4
 67 versicolor                5.6               3.0                4.5               1.5
 68 versicolor                5.8               2.7                4.1               1.0
 69 versicolor                6.2               2.2                4.5               1.5
 70 versicolor                5.6               2.5                3.9               1.1
 71 versicolor                5.9               3.2                4.8               1.8
 72 versicolor                6.1               2.8                4.0               1.3
 73 versicolor                6.3               2.5                4.9               1.5
 74 versicolor                6.1               2.8                4.7               1.2
 75 versicolor                6.4               2.9                4.3               1.3
 76 versicolor                6.6               3.0                4.4               1.4
 77 versicolor                6.8               2.8                4.8               1.4
 78 versicolor                6.7               3.0                5.0               1.7
 79 versicolor                6.0               2.9                4.5               1.5
 80 versicolor                5.7               2.6                3.5               1.0
 81 versicolor                5.5               2.4                3.8               1.1
 82 versicolor                5.5               2.4                3.7               1.0
 83 versicolor                5.8               2.7                3.9               1.2
 84 versicolor                6.0               2.7                5.1               1.6
 85 versicolor                5.4               3.0                4.5               1.5
 86 versicolor                6.0               3.4                4.5               1.6
 87 versicolor                6.7               3.1                4.7               1.5
 88 versicolor                6.3               2.3                4.4               1.3
 89 versicolor                5.6               3.0                4.1               1.3
 90 versicolor                5.5               2.5                4.0               1.3
 91 versicolor                5.5               2.6                4.4               1.2
 92 versicolor                6.1               3.0                4.6               1.4
 93 versicolor                5.8               2.6                4.0               1.2
 94 versicolor                5.0               2.3                3.3               1.0
 95 versicolor                5.6               2.7                4.2               1.3
 96 versicolor                5.7               3.0                4.2               1.2
 97 versicolor                5.7               2.9                4.2               1.3
 98 versicolor                6.2               2.9                4.3               1.3
 99 versicolor                5.1               2.5                3.0               1.1
100 versicolor                5.7               2.8                4.1               1.3
101  virginica                6.3               3.3                6.0               2.5
102  virginica                5.8               2.7                5.1               1.9
103  virginica                7.1               3.0                5.9               2.1
104  virginica                6.3               2.9                5.6               1.8
105  virginica                6.5               3.0                5.8               2.2
106  virginica                7.6               3.0                6.6               2.1
107  virginica                4.9               2.5                4.5               1.7
108  virginica                7.3               2.9                6.3               1.8
109  virginica                6.7               2.5                5.8               1.8
110  virginica                7.2               3.6                6.1               2.5
111  virginica                6.5               3.2                5.1               2.0
112  virginica                6.4               2.7                5.3               1.9
113  virginica                6.8               3.0                5.5               2.1
114  virginica                5.7               2.5                5.0               2.0
115  virginica                5.8               2.8                5.1               2.4
116  virginica                6.4               3.2                5.3               2.3
117  virginica                6.5               3.0                5.5               1.8
118  virginica                7.7               3.8                6.7               2.2
119  virginica                7.7               2.6                6.9               2.3
120  virginica                6.0               2.2                5.0               1.5
121  virginica                6.9               3.2                5.7               2.3
122  virginica                5.6               2.8                4.9               2.0
123  virginica                7.7               2.8                6.7               2.0
124  virginica                6.3               2.7                4.9               1.8
125  virginica                6.7               3.3                5.7               2.1
126  virginica                7.2               3.2                6.0               1.8
127  virginica                6.2               2.8                4.8               1.8
128  virginica                6.1               3.0                4.9               1.8
129  virginica                6.4               2.8                5.6               2.1
130  virginica                7.2               3.0                5.8               1.6
131  virginica                7.4               2.8                6.1               1.9
132  virginica                7.9               3.8                6.4               2.0
133  virginica                6.4               2.8                5.6               2.2
134  virginica                6.3               2.8                5.1               1.5
135  virginica                6.1               2.6                5.6               1.4
136  virginica                7.7               3.0                6.1               2.3
137  virginica                6.3               3.4                5.6               2.4
138  virginica                6.4               3.1                5.5               1.8
139  virginica                6.0               3.0                4.8               1.8
140  virginica                6.9               3.1                5.4               2.1
141  virginica                6.7               3.1                5.6               2.4
142  virginica                6.9               3.1                5.1               2.3
143  virginica                5.8               2.7                5.1               1.9
144  virginica                6.8               3.2                5.9               2.3
145  virginica                6.7               3.3                5.7               2.5
146  virginica                6.7               3.0                5.2               2.3
147  virginica                6.3               2.5                5.0               1.9
148  virginica                6.5               3.0                5.2               2.0
149  virginica                6.2               3.4                5.4               2.3
150  virginica                5.9               3.0                5.1               1.8
</pre></div>
</div>
</div>
</div>
</section>
<section id="diskritisasi-data-dan-cluster-data-menjadi-4-kelas">
<h2><strong>Diskritisasi data dan Cluster data menjadi 4 kelas</strong><a class="headerlink" href="#diskritisasi-data-dan-cluster-data-menjadi-4-kelas" title="Link to this heading">#</a></h2>
<p>Pada tahap ini, dilakukan proses clustering terhadap data Iris menggunakan algoritma KMeans untuk mengelompokkan data ke dalam 4 kelas (cluster) berdasarkan kesamaan fitur-fitur numerik (sepal length, sepal width, petal length, dan petal width). KMeans berjalan dengan menginisialisasi 4 pusat cluster secara acak, kemudian secara iteratif mengelompokkan setiap data ke pusat terdekat dan memperbarui posisi pusat berdasarkan rata-rata data dalam cluster. Setelah proses konvergen, hasil cluster ditambahkan sebagai kolom baru pada data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Salin dataframe untuk diskritisasi</span>
<span class="n">df_discretized</span> <span class="o">=</span> <span class="n">df_iris</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># List fitur numerik yang akan didiskritisasi</span>
<span class="n">fitur_numerik</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>  <span class="c1"># [&#39;sepal length (cm)&#39;, ..., &#39;petal width (cm)&#39;]</span>

<span class="c1"># Lakukan diskritisasi menggunakan KMeans untuk tiap fitur dengan 4 klaster</span>
<span class="k">for</span> <span class="n">fitur</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">:</span>
    <span class="n">X_fitur</span> <span class="o">=</span> <span class="n">df_discretized</span><span class="p">[[</span><span class="n">fitur</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">klaster</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_fitur</span><span class="p">)</span>

    <span class="c1"># Ubah label klaster dari angka ke huruf</span>
    <span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">huruf</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">huruf</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">)}</span>
    <span class="n">klaster_huruf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">klaster</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>

    <span class="c1"># Tambahkan kolom diskrit dengan label huruf</span>
    <span class="n">df_discretized</span><span class="p">[</span><span class="n">fitur</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">klaster_huruf</span>

<span class="c1"># Tampilkan hasil diskritisasi (kolom ID, class, dan kolom diskrit)</span>
<span class="n">kolom_tampil</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_discretized</span><span class="p">[</span><span class="n">kolom_tampil</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id      class sepal length (cm)_diskrit sepal width (cm)_diskrit petal length (cm)_diskrit petal width (cm)_diskrit
  1     setosa                         C                        B                         B                        A
  2     setosa                         C                        A                         B                        A
  3     setosa                         C                        B                         B                        A
  4     setosa                         C                        A                         B                        A
  5     setosa                         C                        B                         B                        A
  6     setosa                         A                        D                         B                        A
  7     setosa                         C                        B                         B                        A
  8     setosa                         C                        B                         B                        A
  9     setosa                         C                        A                         B                        A
 10     setosa                         C                        A                         B                        A
 11     setosa                         A                        D                         B                        A
 12     setosa                         C                        B                         B                        A
 13     setosa                         C                        A                         B                        A
 14     setosa                         C                        A                         B                        A
 15     setosa                         A                        D                         B                        A
 16     setosa                         A                        D                         B                        A
 17     setosa                         A                        D                         B                        A
 18     setosa                         C                        B                         B                        A
 19     setosa                         A                        D                         B                        A
 20     setosa                         C                        D                         B                        A
 21     setosa                         A                        B                         B                        A
 22     setosa                         C                        D                         B                        A
 23     setosa                         C                        B                         B                        A
 24     setosa                         C                        B                         B                        A
 25     setosa                         C                        B                         B                        A
 26     setosa                         C                        A                         B                        A
 27     setosa                         C                        B                         B                        A
 28     setosa                         C                        B                         B                        A
 29     setosa                         C                        B                         B                        A
 30     setosa                         C                        B                         B                        A
 31     setosa                         C                        A                         B                        A
 32     setosa                         A                        B                         B                        A
 33     setosa                         C                        D                         B                        A
 34     setosa                         A                        D                         B                        A
 35     setosa                         C                        A                         B                        A
 36     setosa                         C                        B                         B                        A
 37     setosa                         A                        B                         B                        A
 38     setosa                         C                        B                         B                        A
 39     setosa                         C                        A                         B                        A
 40     setosa                         C                        B                         B                        A
 41     setosa                         C                        B                         B                        A
 42     setosa                         C                        C                         B                        A
 43     setosa                         C                        B                         B                        A
 44     setosa                         C                        B                         B                        A
 45     setosa                         C                        D                         B                        A
 46     setosa                         C                        A                         B                        A
 47     setosa                         C                        D                         B                        A
 48     setosa                         C                        B                         B                        A
 49     setosa                         C                        D                         B                        A
 50     setosa                         C                        B                         B                        A
 51 versicolor                         D                        B                         A                        B
 52 versicolor                         D                        B                         A                        B
 53 versicolor                         D                        A                         A                        B
 54 versicolor                         A                        C                         C                        B
 55 versicolor                         D                        A                         A                        B
 56 versicolor                         A                        A                         A                        B
 57 versicolor                         D                        B                         A                        C
 58 versicolor                         C                        C                         C                        B
 59 versicolor                         D                        A                         A                        B
 60 versicolor                         C                        A                         C                        B
 61 versicolor                         C                        C                         C                        B
 62 versicolor                         A                        A                         C                        B
 63 versicolor                         A                        C                         C                        B
 64 versicolor                         A                        A                         A                        B
 65 versicolor                         A                        A                         C                        B
 66 versicolor                         D                        A                         A                        B
 67 versicolor                         A                        A                         A                        B
 68 versicolor                         A                        A                         C                        B
 69 versicolor                         D                        C                         A                        B
 70 versicolor                         A                        C                         C                        B
 71 versicolor                         A                        B                         A                        C
 72 versicolor                         A                        A                         C                        B
 73 versicolor                         D                        C                         A                        B
 74 versicolor                         A                        A                         A                        B
 75 versicolor                         D                        A                         C                        B
 76 versicolor                         D                        A                         A                        B
 77 versicolor                         D                        A                         A                        B
 78 versicolor                         D                        A                         A                        C
 79 versicolor                         A                        A                         A                        B
 80 versicolor                         A                        C                         C                        B
 81 versicolor                         A                        C                         C                        B
 82 versicolor                         A                        C                         C                        B
 83 versicolor                         A                        A                         C                        B
 84 versicolor                         A                        A                         A                        C
 85 versicolor                         A                        A                         A                        B
 86 versicolor                         A                        B                         A                        C
 87 versicolor                         D                        A                         A                        B
 88 versicolor                         D                        C                         A                        B
 89 versicolor                         A                        A                         C                        B
 90 versicolor                         A                        C                         C                        B
 91 versicolor                         A                        C                         A                        B
 92 versicolor                         A                        A                         A                        B
 93 versicolor                         A                        C                         C                        B
 94 versicolor                         C                        C                         C                        B
 95 versicolor                         A                        A                         C                        B
 96 versicolor                         A                        A                         C                        B
 97 versicolor                         A                        A                         C                        B
 98 versicolor                         D                        A                         C                        B
 99 versicolor                         C                        C                         C                        B
100 versicolor                         A                        A                         C                        B
101  virginica                         D                        B                         D                        D
102  virginica                         A                        A                         A                        C
103  virginica                         B                        A                         D                        D
104  virginica                         D                        A                         D                        C
105  virginica                         D                        A                         D                        D
106  virginica                         B                        A                         D                        D
107  virginica                         C                        C                         A                        C
108  virginica                         B                        A                         D                        C
109  virginica                         D                        C                         D                        C
110  virginica                         B                        B                         D                        D
111  virginica                         D                        B                         A                        C
112  virginica                         D                        A                         A                        C
113  virginica                         D                        A                         D                        D
114  virginica                         A                        C                         A                        C
115  virginica                         A                        A                         A                        D
116  virginica                         D                        B                         A                        D
117  virginica                         D                        A                         D                        C
118  virginica                         B                        D                         D                        D
119  virginica                         B                        C                         D                        D
120  virginica                         A                        C                         A                        B
121  virginica                         D                        B                         D                        D
122  virginica                         A                        A                         A                        C
123  virginica                         B                        A                         D                        C
124  virginica                         D                        A                         A                        C
125  virginica                         D                        B                         D                        D
126  virginica                         B                        B                         D                        C
127  virginica                         D                        A                         A                        C
128  virginica                         A                        A                         A                        C
129  virginica                         D                        A                         D                        D
130  virginica                         B                        A                         D                        C
131  virginica                         B                        A                         D                        C
132  virginica                         B                        D                         D                        C
133  virginica                         D                        A                         D                        D
134  virginica                         D                        A                         A                        B
135  virginica                         A                        C                         D                        B
136  virginica                         B                        A                         D                        D
137  virginica                         D                        B                         D                        D
138  virginica                         D                        A                         D                        C
139  virginica                         A                        A                         A                        C
140  virginica                         D                        A                         D                        D
141  virginica                         D                        A                         D                        D
142  virginica                         D                        A                         A                        D
143  virginica                         A                        A                         A                        C
144  virginica                         D                        B                         D                        D
145  virginica                         D                        B                         D                        D
146  virginica                         D                        A                         A                        D
147  virginica                         D                        C                         A                        C
148  virginica                         D                        A                         A                        C
149  virginica                         D                        B                         D                        D
150  virginica                         A                        A                         A                        C
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2><strong>Klasifikasi menggunakan Naive Bayes</strong><a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>setelah data iris di diskritisasi dan di cluster menjadi 4 kelas, klasifikasi data tadi dengan metode naive bayes. Tujuan dari klasifikasi ini adalah untuk mengevaluasi performa Naive Bayes saat diterapkan pada fitur yang telah didiskretisasi, yaitu mengubah nilai numerik (misalnya panjang kelopak/sepal) menjadi kategori simbolik seperti ‘A’, ‘B’, ‘C’, dan seterusnya. Pendekatan ini cocok digunakan karena Naive Bayes, khususnya varian multinomial atau categorical, dapat bekerja lebih baik dengan data kategori atau frekuensi. Dalam implementasi ini, simbol-simbol diskrit dikonversi kembali ke nilai numerik ordinal (A→0, B→1, dst) agar bisa digunakan oleh model Naive Bayes dari scikit-learn, yang memerlukan input numerik. Dengan metode ini, kita dapat menilai apakah transformasi data dari bentuk kontinu ke diskrit memengaruhi kinerja klasifikasi.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Berdasarkan hasil evaluasi, Naive Bayes masih mampu menghasilkan akurasi yang cukup baik meskipun data telah diubah menjadi bentuk diskrit. Confusion matrix dan classification report menunjukkan bahwa prediksi model tetap cukup akurat untuk sebagian besar kelas, terutama pada kelas yang secara visual dan statistik sangat terpisah seperti setosa. Namun, diskretisasi bisa mengurangi ketelitian dalam membedakan kelas yang saling tumpang tindih seperti versicolor dan virginica, karena informasi numerik yang presisi telah disederhanakan menjadi kategori. Meski demikian, hasil ini menunjukkan bahwa Naive Bayes cukup fleksibel dan tetap efektif ketika digunakan pada data simbolik atau setelah proses pre-processing berbasis diskretisasi. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Siapkan fitur diskrit dan target</span>
<span class="n">fitur_diskrit</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_discretized</span><span class="p">[</span><span class="n">fitur_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">col</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)))</span>  <span class="c1"># A-&gt;0, B-&gt;1, dst</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_discretized</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Split data latih dan uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Inisialisasi dan latih model Naive Bayes</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred_yt</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_yt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_yt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_yt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix:
[[10  0  0]
 [ 0  8  1]
 [ 0  0 11]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       1.00      0.89      0.94         9
   virginica       0.92      1.00      0.96        11

    accuracy                           0.97        30
   macro avg       0.97      0.96      0.97        30
weighted avg       0.97      0.97      0.97        30

Akurasi: 0.9666666666666667
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h2><strong>Klasifikasi Menggunakan DecisionTree</strong><a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Tujuan dari penerapan Decision Tree pada fitur yang telah didiskretisasi adalah untuk mengevaluasi performa model dalam membedakan kelas berdasarkan data kategori yang diubah dari bentuk numerik kontinu menjadi simbol ordinal seperti A, B, C, dan selanjutnya dikonversi ke angka. Dengan menggunakan fitur diskrit, pohon keputusan dapat membentuk aturan yang lebih sederhana dan lebih eksplisit, karena setiap keputusan hanya melibatkan pemisahan berdasarkan level kategori, bukan nilai numerik yang kompleks. Ini sangat sesuai dengan sifat dasar Decision Tree yang bekerja berdasarkan pembelahan data ke dalam cabang berdasarkan kondisi logis (misalnya, apakah fitur = 1 atau tidak).</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Hasil evaluasi menunjukkan bahwa Decision Tree masih mampu memberikan performa klasifikasi yang baik meskipun data yang digunakan telah mengalami diskretisasi. Akurasi model tetap tinggi, dan confusion matrix memperlihatkan bahwa sebagian besar prediksi sesuai dengan label sebenarnya, terutama untuk kelas yang memiliki pola kategori yang konsisten. Visualisasi pohon keputusan memperjelas logika model dalam membuat prediksi berdasarkan fitur-fitur diskrit, dengan cabang-cabang yang menunjukkan urutan pengambilan keputusan berdasarkan nilai kategori numerik. Hal ini sangat membantu dalam interpretasi, karena setiap jalur pada pohon dapat dianggap sebagai aturan klasifikasi yang sederhana dan transparan. Meski begitu, diskretisasi berisiko menghilangkan detail informasi yang bisa berguna dalam pemisahan yang lebih presisi. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil klasifikasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Visualisasi pohon keputusan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span>
               <span class="n">feature_names</span><span class="o">=</span><span class="n">fitur_diskrit</span><span class="p">,</span>
               <span class="n">class_names</span><span class="o">=</span><span class="n">dt_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
               <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi Pohon Keputusan (Decision Tree)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix:
[[10  0  0]
 [ 0  8  1]
 [ 0  0 11]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       1.00      0.89      0.94         9
   virginica       0.92      1.00      0.96        11

    accuracy                           0.97        30
   macro avg       0.97      0.96      0.97        30
weighted avg       0.97      0.97      0.97        30

Akurasi: 0.9666666666666667
</pre></div>
</div>
<img alt="_images/a547c505c2a6bf6388d379c76ae370c10c1beb893bd6a9e74fda1d55c60e1cfc.png" src="_images/a547c505c2a6bf6388d379c76ae370c10c1beb893bd6a9e74fda1d55c60e1cfc.png" />
</div>
</div>
</section>
<section id="hasil-akurasi-keduanya">
<h2><strong>Hasil Akurasi Keduanya</strong><a class="headerlink" href="#hasil-akurasi-keduanya" title="Link to this heading">#</a></h2>
<p>Berdasarkan grafik perbandingan akurasi yang dihasilkan, terlihat seberapa besar akurasi yang dicapai masing-masing model. Jika salah satu batang lebih tinggi, maka model tersebut memiliki performa lebih baik dalam mengenali pola pada data uji. Misalnya, jika Decision Tree menunjukkan akurasi yang lebih tinggi daripada Naive Bayes, berarti model tersebut lebih tepat dalam menangani kompleksitas dan struktur data pada kasus ini. Namun jika Naive Bayes lebih unggul, hal ini menunjukkan bahwa pendekatan probabilistiknya lebih efisien, terutama ketika fitur memiliki hubungan independen. Grafik ini memberikan kesimpulan visual yang ringkas bahwa akurasi adalah faktor penting, namun tetap perlu dipertimbangkan bersama aspek lain seperti kompleksitas model dan interpretabilitas. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">akurasi_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">akurasi_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># === Cetak akurasi kedua model ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Perbandingan Akurasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Naive Bayes     : </span><span class="si">{</span><span class="n">akurasi_nb</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Decision Tree   : </span><span class="si">{</span><span class="n">akurasi_dt</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Buat DataFrame untuk visualisasi</span>
<span class="n">accuracy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Model&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">akurasi_nb</span><span class="p">,</span> <span class="n">akurasi_dt</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">:</span> <span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">:</span> <span class="s1">&#39;lightgreen&#39;</span><span class="p">}</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">accuracy_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi Model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Perbandingan Akurasi ===
Akurasi Naive Bayes     : 0.9667
Akurasi Decision Tree   : 0.9667
</pre></div>
</div>
<img alt="_images/6c24bb506fe0ab7889255d663d20abbbbce3b4ee5aee65713ccb9dbabc380f58.png" src="_images/6c24bb506fe0ab7889255d663d20abbbbce3b4ee5aee65713ccb9dbabc380f58.png" />
</div>
</div>
</section>
</section>
<section id="klasifikasi-3">
<h1><strong>Klasifikasi 3</strong><a class="headerlink" href="#klasifikasi-3" title="Link to this heading">#</a></h1>
<section id="diskritisasi-data-dengan-equal-width-binning">
<h2><strong>Diskritisasi Data dengan Equal Width-Binning</strong><a class="headerlink" href="#diskritisasi-data-dengan-equal-width-binning" title="Link to this heading">#</a></h2>
<section id="langkah-langkah-equal-width-binning-untuk-data-iris-sebagai-berikut">
<h3><strong>Langkah-langkah Equal Width-Binning untuk data Iris Sebagai berikut:</strong><a class="headerlink" href="#langkah-langkah-equal-width-binning-untuk-data-iris-sebagai-berikut" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Cari Nilai Minimum dan Maksimum</strong></p></li>
<li><p><strong>Hitung lebar Bin</strong></p></li>
<li><p><strong>Tentukan batas-batas Bin</strong></p></li>
<li><p><strong>Tampilkan hasil akhir (ID, class, dan fitur diskrit)</strong></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Jumlah bin</span>
<span class="n">jumlah_bin</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># Salin dataframe</span>
<span class="n">df_diskrit</span> <span class="o">=</span> <span class="n">df_iris</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Diskritisasi Equal Width per fitur</span>
<span class="k">for</span> <span class="n">fitur</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Diskritisasi Fitur: </span><span class="si">{</span><span class="n">fitur</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>

    <span class="c1"># Langkah 1: cari nilai minimum dan maksimum</span>
    <span class="n">nilai_min</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">nilai_max</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nilai Minimum : </span><span class="si">{</span><span class="n">nilai_min</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nilai Maksimum: </span><span class="si">{</span><span class="n">nilai_max</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Langkah 2: hitung lebar bin</span>
    <span class="n">lebar_bin</span> <span class="o">=</span> <span class="p">(</span><span class="n">nilai_max</span> <span class="o">-</span> <span class="n">nilai_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">jumlah_bin</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lebar Bin     : </span><span class="si">{</span><span class="n">lebar_bin</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Langkah 3: tentukan batas-batas bin</span>
    <span class="n">batas_bin</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">nilai_min</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">lebar_bin</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">jumlah_bin</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batas-batas   : </span><span class="si">{</span><span class="n">batas_bin</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Langkah 4: buat kategori (interval) berdasarkan bin</span>
    <span class="n">label_bin</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">]</span>
    <span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">batas_bin</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label_bin</span><span class="p">,</span> <span class="n">include_lowest</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Tampilkan hasil akhir (ID, class, dan fitur diskrit)</span>
<span class="n">kolom_diskrit</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Data Hasil Diskritisasi (Equal Width) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_diskrit</span><span class="p">[</span><span class="n">kolom_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Diskritisasi Fitur: sepal length (cm) ===
Nilai Minimum : 4.3
Nilai Maksimum: 7.9
Lebar Bin     : 0.9000000000000001
Batas-batas   : [4.3, 5.2, 6.1, 7.0, 7.9]

=== Diskritisasi Fitur: sepal width (cm) ===
Nilai Minimum : 2.0
Nilai Maksimum: 4.4
Lebar Bin     : 0.6000000000000001
Batas-batas   : [2.0, 2.6, 3.2, 3.8, 4.4]

=== Diskritisasi Fitur: petal length (cm) ===
Nilai Minimum : 1.0
Nilai Maksimum: 6.9
Lebar Bin     : 1.475
Batas-batas   : [1.0, 2.48, 3.95, 5.43, 6.9]

=== Diskritisasi Fitur: petal width (cm) ===
Nilai Minimum : 0.1
Nilai Maksimum: 2.5
Lebar Bin     : 0.6
Batas-batas   : [0.1, 0.7, 1.3, 1.9, 2.5]

=== Data Hasil Diskritisasi (Equal Width) ===
 id      class sepal length (cm)_diskrit sepal width (cm)_diskrit petal length (cm)_diskrit petal width (cm)_diskrit
  1     setosa                         A                        C                         A                        A
  2     setosa                         A                        B                         A                        A
  3     setosa                         A                        B                         A                        A
  4     setosa                         A                        B                         A                        A
  5     setosa                         A                        C                         A                        A
  6     setosa                         B                        D                         A                        A
  7     setosa                         A                        C                         A                        A
  8     setosa                         A                        C                         A                        A
  9     setosa                         A                        B                         A                        A
 10     setosa                         A                        B                         A                        A
 11     setosa                         B                        C                         A                        A
 12     setosa                         A                        C                         A                        A
 13     setosa                         A                        B                         A                        A
 14     setosa                         A                        B                         A                        A
 15     setosa                         B                        D                         A                        A
 16     setosa                         B                        D                         A                        A
 17     setosa                         B                        D                         A                        A
 18     setosa                         A                        C                         A                        A
 19     setosa                         B                        C                         A                        A
 20     setosa                         A                        C                         A                        A
 21     setosa                         B                        C                         A                        A
 22     setosa                         A                        C                         A                        A
 23     setosa                         A                        C                         A                        A
 24     setosa                         A                        C                         A                        A
 25     setosa                         A                        C                         A                        A
 26     setosa                         A                        B                         A                        A
 27     setosa                         A                        C                         A                        A
 28     setosa                         A                        C                         A                        A
 29     setosa                         A                        C                         A                        A
 30     setosa                         A                        B                         A                        A
 31     setosa                         A                        B                         A                        A
 32     setosa                         B                        C                         A                        A
 33     setosa                         A                        D                         A                        A
 34     setosa                         B                        D                         A                        A
 35     setosa                         A                        B                         A                        A
 36     setosa                         A                        B                         A                        A
 37     setosa                         B                        C                         A                        A
 38     setosa                         A                        C                         A                        A
 39     setosa                         A                        B                         A                        A
 40     setosa                         A                        C                         A                        A
 41     setosa                         A                        C                         A                        A
 42     setosa                         A                        A                         A                        A
 43     setosa                         A                        B                         A                        A
 44     setosa                         A                        C                         A                        A
 45     setosa                         A                        C                         A                        A
 46     setosa                         A                        B                         A                        A
 47     setosa                         A                        C                         A                        A
 48     setosa                         A                        B                         A                        A
 49     setosa                         B                        C                         A                        A
 50     setosa                         A                        C                         A                        A
 51 versicolor                         C                        B                         C                        C
 52 versicolor                         C                        B                         C                        C
 53 versicolor                         C                        B                         C                        C
 54 versicolor                         B                        A                         C                        B
 55 versicolor                         C                        B                         C                        C
 56 versicolor                         B                        B                         C                        B
 57 versicolor                         C                        C                         C                        C
 58 versicolor                         A                        A                         B                        B
 59 versicolor                         C                        B                         C                        B
 60 versicolor                         A                        B                         B                        C
 61 versicolor                         A                        A                         B                        B
 62 versicolor                         B                        B                         C                        C
 63 versicolor                         B                        A                         C                        B
 64 versicolor                         B                        B                         C                        C
 65 versicolor                         B                        B                         B                        B
 66 versicolor                         C                        B                         C                        C
 67 versicolor                         B                        B                         C                        C
 68 versicolor                         B                        B                         C                        B
 69 versicolor                         C                        A                         C                        C
 70 versicolor                         B                        A                         B                        B
 71 versicolor                         B                        B                         C                        C
 72 versicolor                         B                        B                         C                        B
 73 versicolor                         C                        A                         C                        C
 74 versicolor                         B                        B                         C                        B
 75 versicolor                         C                        B                         C                        B
 76 versicolor                         C                        B                         C                        C
 77 versicolor                         C                        B                         C                        C
 78 versicolor                         C                        B                         C                        C
 79 versicolor                         B                        B                         C                        C
 80 versicolor                         B                        A                         B                        B
 81 versicolor                         B                        A                         B                        B
 82 versicolor                         B                        A                         B                        B
 83 versicolor                         B                        B                         B                        B
 84 versicolor                         B                        B                         C                        C
 85 versicolor                         B                        B                         C                        C
 86 versicolor                         B                        C                         C                        C
 87 versicolor                         C                        B                         C                        C
 88 versicolor                         C                        A                         C                        B
 89 versicolor                         B                        B                         C                        B
 90 versicolor                         B                        A                         C                        B
 91 versicolor                         B                        A                         C                        B
 92 versicolor                         B                        B                         C                        C
 93 versicolor                         B                        A                         C                        B
 94 versicolor                         A                        A                         B                        B
 95 versicolor                         B                        B                         C                        B
 96 versicolor                         B                        B                         C                        B
 97 versicolor                         B                        B                         C                        B
 98 versicolor                         C                        B                         C                        B
 99 versicolor                         A                        A                         B                        B
100 versicolor                         B                        B                         C                        B
101  virginica                         C                        C                         D                        D
102  virginica                         B                        B                         C                        C
103  virginica                         D                        B                         D                        D
104  virginica                         C                        B                         D                        C
105  virginica                         C                        B                         D                        D
106  virginica                         D                        B                         D                        D
107  virginica                         A                        A                         C                        C
108  virginica                         D                        B                         D                        C
109  virginica                         C                        A                         D                        C
110  virginica                         D                        C                         D                        D
111  virginica                         C                        B                         C                        D
112  virginica                         C                        B                         C                        C
113  virginica                         C                        B                         D                        D
114  virginica                         B                        A                         C                        D
115  virginica                         B                        B                         C                        D
116  virginica                         C                        B                         C                        D
117  virginica                         C                        B                         D                        C
118  virginica                         D                        C                         D                        D
119  virginica                         D                        A                         D                        D
120  virginica                         B                        A                         C                        C
121  virginica                         C                        B                         D                        D
122  virginica                         B                        B                         C                        D
123  virginica                         D                        B                         D                        D
124  virginica                         C                        B                         C                        C
125  virginica                         C                        C                         D                        D
126  virginica                         D                        B                         D                        C
127  virginica                         C                        B                         C                        C
128  virginica                         B                        B                         C                        C
129  virginica                         C                        B                         D                        D
130  virginica                         D                        B                         D                        C
131  virginica                         D                        B                         D                        C
132  virginica                         D                        C                         D                        D
133  virginica                         C                        B                         D                        D
134  virginica                         C                        B                         C                        C
135  virginica                         B                        A                         D                        C
136  virginica                         D                        B                         D                        D
137  virginica                         C                        C                         D                        D
138  virginica                         C                        B                         D                        C
139  virginica                         B                        B                         C                        C
140  virginica                         C                        B                         C                        D
141  virginica                         C                        B                         D                        D
142  virginica                         C                        B                         C                        D
143  virginica                         B                        B                         C                        C
144  virginica                         C                        B                         D                        D
145  virginica                         C                        C                         D                        D
146  virginica                         C                        B                         C                        D
147  virginica                         C                        A                         C                        C
148  virginica                         C                        B                         C                        D
149  virginica                         C                        C                         C                        D
150  virginica                         B                        B                         C                        C
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id4">
<h2><strong>Klasifikasi Menggunakan Naive Bayes</strong><a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Tujuan dari proses klasifikasi ini adalah untuk mengevaluasi performa algoritma Naive Bayes ketika digunakan pada data yang telah mengalami proses diskretisasi umum, yaitu mengubah nilai numerik menjadi label simbolik (A, B, C, dst). Diskretisasi dilakukan pada seluruh fitur dalam dataset, yang kemudian dikonversi kembali ke bentuk numerik ordinal agar dapat diproses oleh model Naive Bayes. Langkah ini diambil untuk melihat bagaimana model probabilistik ini bekerja ketika data kehilangan nilai numerik presisi dan digantikan oleh kategori. Metode ini sering digunakan dalam situasi ketika data asli bersifat kontinu, namun kita ingin menyederhanakannya atau mempersiapkannya untuk algoritma yang lebih cocok dengan data diskrit.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Hasil evaluasi menunjukkan bahwa Naive Bayes tetap mampu melakukan klasifikasi dengan cukup baik, meskipun bekerja dengan fitur-fitur yang telah disederhanakan menjadi bentuk diskrit. Confusion matrix dan classification report memperlihatkan bahwa model masih dapat mengidentifikasi kelas utama dengan cukup akurat, meskipun mungkin terjadi penurunan kinerja pada kelas yang memiliki nilai fitur yang sebelumnya sangat dekat atau tumpang tindih. Akurasi yang dihasilkan tetap kompetitif, membuktikan bahwa Naive Bayes cukup fleksibel dalam menghadapi perubahan representasi data. Namun, seperti pada umumnya diskretisasi, ada risiko informasi penting hilang, sehingga perlu dipertimbangkan konteks penggunaannya. Berikut Implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ambil fitur diskrit dan label</span>
<span class="n">fitur_diskrit</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">]</span>
<span class="n">X_nb</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">kolom</span><span class="p">:</span> <span class="n">kolom</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Split data</span>
<span class="n">X_train_nb</span><span class="p">,</span> <span class="n">X_test_nb</span><span class="p">,</span> <span class="n">y_train_nb</span><span class="p">,</span> <span class="n">y_test_nb</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_nb</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Buat dan latih model Naive Bayes</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_nb</span><span class="p">,</span> <span class="n">y_train_nb</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred_Tb</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_nb</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Evaluasi Naive Bayes (Equal Width) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_nb</span><span class="p">,</span> <span class="n">y_pred_Tb</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_nb</span><span class="p">,</span> <span class="n">y_pred_Tb</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_nb</span><span class="p">,</span> <span class="n">y_pred_Tb</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Evaluasi Naive Bayes (Equal Width) ===
Confusion Matrix:
[[10  0  0]
 [ 0  7  2]
 [ 0  1 10]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.88      0.78      0.82         9
   virginica       0.83      0.91      0.87        11

    accuracy                           0.90        30
   macro avg       0.90      0.90      0.90        30
weighted avg       0.90      0.90      0.90        30

Akurasi: 0.9
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h2><strong>Klasifikasi Menggunakan DecisionTree</strong><a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Tujuan dari eksperimen ini adalah untuk menerapkan algoritma Decision Tree pada dataset Iris yang telah melalui proses diskretisasi fitur. Setiap fitur numerik pada dataset diubah ke dalam bentuk simbolik (seperti A–D) dan kemudian dikonversi menjadi angka ordinal agar dapat digunakan sebagai input model. Pendekatan ini bertujuan untuk menguji bagaimana performa Decision Tree dalam mengklasifikasikan data simbolik, serta mengevaluasi apakah pemangkasan nilai numerik menjadi kategori masih dapat mempertahankan kemampuan pemodelan terhadap pola data. Decision Tree sangat cocok untuk data kategori karena dapat membuat keputusan berdasarkan nilai diskrit secara langsung, sehingga metode ini sangat relevan untuk dicoba dalam konteks ini.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Berdasarkan hasil evaluasi, model Decision Tree menunjukkan kinerja klasifikasi yang cukup baik, dengan akurasi yang relatif tinggi meskipun bekerja pada data hasil diskretisasi. Confusion matrix menunjukkan distribusi prediksi benar dan salah antar kelas, sedangkan classification report memberi gambaran detail tentang precision, recall, dan F1-score untuk tiap kelas. Visualisasi pohon keputusan yang dihasilkan juga memberikan interpretasi yang mudah dipahami mengenai bagaimana model mengambil keputusan dari fitur-fitur diskrit yang ada. Hasil ini menunjukkan bahwa Decision Tree merupakan model yang robust terhadap perubahan bentuk data, terutama pada data kategorikal atau hasil diskretisasi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ambil fitur diskrit dan label (bisa gunakan kembali variabel yang sama)</span>
<span class="n">X_dt</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="n">fitur_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">kolom</span><span class="p">:</span> <span class="n">kolom</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_diskrit</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Split data</span>
<span class="n">X_train_dt</span><span class="p">,</span> <span class="n">X_test_dt</span><span class="p">,</span> <span class="n">y_train_dt</span><span class="p">,</span> <span class="n">y_test_dt</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_dt</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Buat dan latih model Decision Tree</span>
<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_dt</span><span class="p">,</span> <span class="n">y_train_dt</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred_dd</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_dt</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Evaluasi Decision Tree (Equal Width) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dd</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dd</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dd</span><span class="p">))</span>

<span class="c1"># Visualisasi pohon keputusan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span>
               <span class="n">feature_names</span><span class="o">=</span><span class="n">fitur_diskrit</span><span class="p">,</span>
               <span class="n">class_names</span><span class="o">=</span><span class="n">dt_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
               <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi Pohon Keputusan (Decision Tree) - Equal Width-Binning&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Evaluasi Decision Tree (Equal Width) ===
Confusion Matrix:
[[10  0  0]
 [ 0  9  0]
 [ 0  1 10]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.90      1.00      0.95         9
   virginica       1.00      0.91      0.95        11

    accuracy                           0.97        30
   macro avg       0.97      0.97      0.97        30
weighted avg       0.97      0.97      0.97        30

Akurasi: 0.9666666666666667
</pre></div>
</div>
<img alt="_images/68dbf8414a820e5c85839592db342663cf1c1177dc9562c0dc25317ee69825b8.png" src="_images/68dbf8414a820e5c85839592db342663cf1c1177dc9562c0dc25317ee69825b8.png" />
</div>
</div>
</section>
<section id="id6">
<h2><strong>Hasil Akurasi Keduanya</strong><a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>Hasil evaluasi menunjukkan tingkat akurasi yang berbeda antara kedua model. Dari visualisasi dan perhitungan akurasi, dapat dilihat bahwa Decision Tree umumnya memberikan hasil akurasi yang sedikit lebih tinggi dibandingkan Naive Bayes dalam konteks data diskrit ini. Hal ini disebabkan karena Decision Tree secara alami sangat cocok untuk bekerja dengan data kategorikal, di mana setiap nilai bisa langsung digunakan sebagai pemisah keputusan. Sebaliknya, Naive Bayes mengasumsikan independensi antar fitur dan lebih optimal untuk distribusi data kontinu, sehingga performanya bisa menurun ketika informasi numerik diringkas menjadi kategori. Namun, keduanya tetap menunjukkan akurasi yang baik secara keseluruhan, yang menandakan bahwa data Iris tetap informatif meskipun telah didiskretisasi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hitung akurasi masing-masing model</span>
<span class="n">acc_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_Tb</span><span class="p">)</span>
<span class="n">acc_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dd</span><span class="p">)</span>


<span class="c1"># === Cetak akurasi kedua model ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Perbandingan Akurasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Naive Bayes     : </span><span class="si">{</span><span class="n">acc_nb</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Decision Tree   : </span><span class="si">{</span><span class="n">acc_dt</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Buat DataFrame untuk visualisasi</span>
<span class="n">accuracy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Model&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">acc_nb</span><span class="p">,</span> <span class="n">acc_dt</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">:</span> <span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">:</span> <span class="s1">&#39;lightgreen&#39;</span><span class="p">}</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">accuracy_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi Model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Perbandingan Akurasi ===
Akurasi Naive Bayes     : 0.9000
Akurasi Decision Tree   : 0.9667
</pre></div>
</div>
<img alt="_images/6bf395e601246ffbe8e088b2f915b11ebbfd0c6dd87fee2b4ac43fa3aa26e27b.png" src="_images/6bf395e601246ffbe8e088b2f915b11ebbfd0c6dd87fee2b4ac43fa3aa26e27b.png" />
</div>
</div>
</section>
</section>
<section id="klasifikasi-4">
<h1><strong>Klasifikasi 4</strong><a class="headerlink" href="#klasifikasi-4" title="Link to this heading">#</a></h1>
<section id="klasifikasi-data-dengan-equal-frequency">
<h2><strong>Klasifikasi data dengan Equal Frequency</strong><a class="headerlink" href="#klasifikasi-data-dengan-equal-frequency" title="Link to this heading">#</a></h2>
</section>
<section id="langkah-langkah-equal-frequency-untuk-data-iris-sebagai-berikut">
<h2><strong>Langkah-langkah Equal Frequency untuk data Iris sebagai berikut:</strong><a class="headerlink" href="#langkah-langkah-equal-frequency-untuk-data-iris-sebagai-berikut" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>urutkan data secara ascending</strong></p></li>
<li><p><strong>Hitung Posisi kuantil</strong></p></li>
<li><p><strong>Cari nilai kuantil dari data</strong></p></li>
<li><p><strong>Buat batas interval</strong></p></li>
<li><p><strong>Kelompokkan data ke dalam bins</strong></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inisialisasi</span>
<span class="n">df_iris</span> <span class="o">=</span> <span class="n">get_iris_data</span><span class="p">()</span>
<span class="n">fitur_numerik</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">feature_names</span>
<span class="n">jumlah_bin</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">df_eqfreq</span> <span class="o">=</span> <span class="n">df_iris</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-6</span>  <span class="c1"># nilai kecil untuk hindari duplikasi batas</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Diskritisasi Equal Frequency (4 Bin) ===&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">fitur</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Fitur: </span><span class="si">{</span><span class="n">fitur</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">data_fitur</span> <span class="o">=</span> <span class="n">df_eqfreq</span><span class="p">[</span><span class="n">fitur</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># 1. Urutkan data</span>
    <span class="n">data_sorted</span> <span class="o">=</span> <span class="n">data_fitur</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data urut (5 teratas):&quot;</span><span class="p">,</span> <span class="n">data_sorted</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="c1"># 2. Hitung posisi kuantil</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_sorted</span><span class="p">)</span>
    <span class="n">posisi_kuantil</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">n</span> <span class="o">/</span> <span class="n">jumlah_bin</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">jumlah_bin</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Posisi kuantil:&quot;</span><span class="p">,</span> <span class="n">posisi_kuantil</span><span class="p">)</span>

    <span class="c1"># 3. Ambil nilai kuantil dari posisi</span>
    <span class="n">nilai_kuantil</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_sorted</span><span class="p">[</span><span class="n">pos</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">posisi_kuantil</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nilai kuantil:&quot;</span><span class="p">,</span> <span class="n">nilai_kuantil</span><span class="p">)</span>

    <span class="c1"># 4. Buat batas bin (hindari batas duplikat dengan epsilon)</span>
    <span class="n">batas</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_sorted</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">]</span> <span class="o">+</span> <span class="n">nilai_kuantil</span> <span class="o">+</span> <span class="p">[</span><span class="n">data_sorted</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batas bin:&quot;</span><span class="p">,</span> <span class="n">batas</span><span class="p">)</span>

    <span class="c1"># 5. Diskritisasi ke dalam bin-label A-D</span>
    <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">]</span>
    <span class="n">df_eqfreq</span><span class="p">[</span><span class="n">fitur</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df_eqfreq</span><span class="p">[</span><span class="n">fitur</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">batas</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># 6. Tampilkan hasil akhir</span>
<span class="n">kolom_diskrit</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Hasil Akhir Diskritisasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_eqfreq</span><span class="p">[</span><span class="n">kolom_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Diskritisasi Equal Frequency (4 Bin) ===

Fitur: sepal length (cm)
Data urut (5 teratas): [4.3 4.4 4.4 4.4 4.5]
Posisi kuantil: [38, 75, 113]
Nilai kuantil: [np.float64(5.1), np.float64(5.8), np.float64(6.4)]
Batas bin: [4.299999, np.float64(5.1), np.float64(5.8), np.float64(6.4), 7.9000010000000005]

Fitur: sepal width (cm)
Data urut (5 teratas): [2.  2.2 2.2 2.2 2.3]
Posisi kuantil: [38, 75, 113]
Nilai kuantil: [np.float64(2.8), np.float64(3.0), np.float64(3.3)]
Batas bin: [1.999999, np.float64(2.8), np.float64(3.0), np.float64(3.3), 4.4000010000000005]

Fitur: petal length (cm)
Data urut (5 teratas): [1.  1.1 1.2 1.2 1.3]
Posisi kuantil: [38, 75, 113]
Nilai kuantil: [np.float64(1.6), np.float64(4.3), np.float64(5.1)]
Batas bin: [0.999999, np.float64(1.6), np.float64(4.3), np.float64(5.1), 6.9000010000000005]

Fitur: petal width (cm)
Data urut (5 teratas): [0.1 0.1 0.1 0.1 0.1]
Posisi kuantil: [38, 75, 113]
Nilai kuantil: [np.float64(0.3), np.float64(1.3), np.float64(1.8)]
Batas bin: [0.099999, np.float64(0.3), np.float64(1.3), np.float64(1.8), 2.500001]

=== Hasil Akhir Diskritisasi ===
 id      class sepal length (cm)_diskrit sepal width (cm)_diskrit petal length (cm)_diskrit petal width (cm)_diskrit
  1     setosa                         A                        D                         A                        A
  2     setosa                         A                        B                         A                        A
  3     setosa                         A                        C                         A                        A
  4     setosa                         A                        C                         A                        A
  5     setosa                         A                        D                         A                        A
  6     setosa                         B                        D                         B                        B
  7     setosa                         A                        D                         A                        A
  8     setosa                         A                        D                         A                        A
  9     setosa                         A                        B                         A                        A
 10     setosa                         A                        C                         A                        A
 11     setosa                         B                        D                         A                        A
 12     setosa                         A                        D                         A                        A
 13     setosa                         A                        B                         A                        A
 14     setosa                         A                        B                         A                        A
 15     setosa                         B                        D                         A                        A
 16     setosa                         B                        D                         A                        B
 17     setosa                         B                        D                         A                        B
 18     setosa                         A                        D                         A                        A
 19     setosa                         B                        D                         B                        A
 20     setosa                         A                        D                         A                        A
 21     setosa                         B                        D                         B                        A
 22     setosa                         A                        D                         A                        B
 23     setosa                         A                        D                         A                        A
 24     setosa                         A                        C                         B                        B
 25     setosa                         A                        D                         B                        A
 26     setosa                         A                        B                         A                        A
 27     setosa                         A                        D                         A                        B
 28     setosa                         B                        D                         A                        A
 29     setosa                         B                        D                         A                        A
 30     setosa                         A                        C                         A                        A
 31     setosa                         A                        C                         A                        A
 32     setosa                         B                        D                         A                        B
 33     setosa                         B                        D                         A                        A
 34     setosa                         B                        D                         A                        A
 35     setosa                         A                        C                         A                        A
 36     setosa                         A                        C                         A                        A
 37     setosa                         B                        D                         A                        A
 38     setosa                         A                        D                         A                        A
 39     setosa                         A                        B                         A                        A
 40     setosa                         A                        D                         A                        A
 41     setosa                         A                        D                         A                        A
 42     setosa                         A                        A                         A                        A
 43     setosa                         A                        C                         A                        A
 44     setosa                         A                        D                         A                        B
 45     setosa                         A                        D                         B                        B
 46     setosa                         A                        B                         A                        A
 47     setosa                         A                        D                         A                        A
 48     setosa                         A                        C                         A                        A
 49     setosa                         B                        D                         A                        A
 50     setosa                         A                        C                         A                        A
 51 versicolor                         D                        C                         C                        C
 52 versicolor                         C                        C                         C                        C
 53 versicolor                         D                        C                         C                        C
 54 versicolor                         B                        A                         B                        B
 55 versicolor                         D                        A                         C                        C
 56 versicolor                         B                        A                         C                        B
 57 versicolor                         C                        C                         C                        C
 58 versicolor                         A                        A                         B                        B
 59 versicolor                         D                        B                         C                        B
 60 versicolor                         B                        A                         B                        C
 61 versicolor                         A                        A                         B                        B
 62 versicolor                         C                        B                         B                        C
 63 versicolor                         C                        A                         B                        B
 64 versicolor                         C                        B                         C                        C
 65 versicolor                         B                        B                         B                        B
 66 versicolor                         D                        C                         C                        C
 67 versicolor                         B                        B                         C                        C
 68 versicolor                         B                        A                         B                        B
 69 versicolor                         C                        A                         C                        C
 70 versicolor                         B                        A                         B                        B
 71 versicolor                         C                        C                         C                        C
 72 versicolor                         C                        A                         B                        B
 73 versicolor                         C                        A                         C                        C
 74 versicolor                         C                        A                         C                        B
 75 versicolor                         C                        B                         B                        B
 76 versicolor                         D                        B                         C                        C
 77 versicolor                         D                        A                         C                        C
 78 versicolor                         D                        B                         C                        C
 79 versicolor                         C                        B                         C                        C
 80 versicolor                         B                        A                         B                        B
 81 versicolor                         B                        A                         B                        B
 82 versicolor                         B                        A                         B                        B
 83 versicolor                         B                        A                         B                        B
 84 versicolor                         C                        A                         C                        C
 85 versicolor                         B                        B                         C                        C
 86 versicolor                         C                        D                         C                        C
 87 versicolor                         D                        C                         C                        C
 88 versicolor                         C                        A                         C                        B
 89 versicolor                         B                        B                         B                        B
 90 versicolor                         B                        A                         B                        B
 91 versicolor                         B                        A                         C                        B
 92 versicolor                         C                        B                         C                        C
 93 versicolor                         B                        A                         B                        B
 94 versicolor                         A                        A                         B                        B
 95 versicolor                         B                        A                         B                        B
 96 versicolor                         B                        B                         B                        B
 97 versicolor                         B                        B                         B                        B
 98 versicolor                         C                        B                         B                        B
 99 versicolor                         A                        A                         B                        B
100 versicolor                         B                        A                         B                        B
101  virginica                         C                        C                         D                        D
102  virginica                         B                        A                         C                        D
103  virginica                         D                        B                         D                        D
104  virginica                         C                        B                         D                        C
105  virginica                         D                        B                         D                        D
106  virginica                         D                        B                         D                        D
107  virginica                         A                        A                         C                        C
108  virginica                         D                        B                         D                        C
109  virginica                         D                        A                         D                        C
110  virginica                         D                        D                         D                        D
111  virginica                         D                        C                         C                        D
112  virginica                         C                        A                         D                        D
113  virginica                         D                        B                         D                        D
114  virginica                         B                        A                         C                        D
115  virginica                         B                        A                         C                        D
116  virginica                         C                        C                         D                        D
117  virginica                         D                        B                         D                        C
118  virginica                         D                        D                         D                        D
119  virginica                         D                        A                         D                        D
120  virginica                         C                        A                         C                        C
121  virginica                         D                        C                         D                        D
122  virginica                         B                        A                         C                        D
123  virginica                         D                        A                         D                        D
124  virginica                         C                        A                         C                        C
125  virginica                         D                        C                         D                        D
126  virginica                         D                        C                         D                        C
127  virginica                         C                        A                         C                        C
128  virginica                         C                        B                         C                        C
129  virginica                         C                        A                         D                        D
130  virginica                         D                        B                         D                        C
131  virginica                         D                        A                         D                        D
132  virginica                         D                        D                         D                        D
133  virginica                         C                        A                         D                        D
134  virginica                         C                        A                         C                        C
135  virginica                         C                        A                         D                        C
136  virginica                         D                        B                         D                        D
137  virginica                         C                        D                         D                        D
138  virginica                         C                        C                         D                        C
139  virginica                         C                        B                         C                        C
140  virginica                         D                        C                         D                        D
141  virginica                         D                        C                         D                        D
142  virginica                         D                        C                         C                        D
143  virginica                         B                        A                         C                        D
144  virginica                         D                        C                         D                        D
145  virginica                         D                        C                         D                        D
146  virginica                         D                        B                         D                        D
147  virginica                         C                        A                         C                        D
148  virginica                         D                        B                         D                        D
149  virginica                         C                        D                         D                        D
150  virginica                         C                        B                         C                        C
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h2><strong>Klasifikasi Menggunakan Naive Bayes</strong><a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Tujuan dari eksperimen ini adalah untuk mengevaluasi kinerja model Naive Bayes saat bekerja dengan data yang telah didiskretisasi menggunakan metode Equal Frequency. Diskretisasi ini membagi setiap fitur numerik menjadi beberapa kategori yang masing-masing berisi jumlah data yang hampir sama. Teknik ini dilakukan untuk menyederhanakan kompleksitas data dan mengubah fitur numerik menjadi fitur kategorikal, yang kemudian dikonversi menjadi nilai ordinal agar bisa digunakan dalam proses pelatihan model Naive Bayes. Langkah ini juga membantu menilai sejauh mana model probabilistik seperti Naive Bayes mampu menggeneralisasi dari data yang kehilangan informasi kuantitatif aslinya.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Berdasarkan hasil evaluasi, model Naive Bayes menunjukkan tingkat akurasi yang cukup baik, meskipun terdapat beberapa kesalahan klasifikasi. Confusion matrix dan classification report memperlihatkan bahwa sebagian besar prediksi kelas berhasil dilakukan dengan benar, namun ada beberapa instance yang salah klasifikasi, terutama di antara kelas yang mirip secara fitur. Ini menunjukkan bahwa Naive Bayes masih cukup efektif dalam mengenali pola meskipun data telah mengalami diskretisasi yang mengurangi ketelitian nilai aslinya. Namun demikian, hilangnya informasi numerik yang spesifik kemungkinan mempengaruhi sensitivitas model terhadap perbedaan halus antar kelas. Berikut Implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Konversi label A-D ke angka 0-3 ===</span>
<span class="n">fitur_diskrit</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="o">+</span> <span class="s2">&quot;_diskrit&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fitur_numerik</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_eqfreq</span><span class="p">[</span><span class="n">fitur_diskrit</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">kolom</span><span class="p">:</span> <span class="n">kolom</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_eqfreq</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># === Split data ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Buat dan latih model Naive Bayes ===</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># === Prediksi ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Evaluasi ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Evaluasi Naive Bayes Setelah Diskritisasi Equal Frequency ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Evaluasi Naive Bayes Setelah Diskritisasi Equal Frequency ===

Confusion Matrix:
[[10  0  0]
 [ 0  8  1]
 [ 0  1 10]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.89      0.89      0.89         9
   virginica       0.91      0.91      0.91        11

    accuracy                           0.93        30
   macro avg       0.93      0.93      0.93        30
weighted avg       0.93      0.93      0.93        30

Akurasi: 0.9333333333333333
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifisikas-dengan-decisiontree">
<h2><strong>Klasifisikas dengan DecisionTree</strong><a class="headerlink" href="#klasifisikas-dengan-decisiontree" title="Link to this heading">#</a></h2>
<p><strong>IDENTIFIKASI</strong></p>
<p>Penerapan algoritma Decision Tree pada data yang telah didiskretisasi menggunakan metode Equal Frequency bertujuan untuk mengevaluasi bagaimana performa model pohon keputusan dalam mengklasifikasi data kategorikal ordinal. Diskretisasi ini membagi fitur numerik menjadi sejumlah interval dengan jumlah data yang seimbang, dan setiap nilai kategori kemudian dikonversi ke dalam angka agar bisa diproses oleh model. Penggunaan Decision Tree pada data diskrit memungkinkan visualisasi struktur pohon yang lebih sederhana, serta menguji apakah pemangkasan data numerik ke dalam kategori tetap dapat mempertahankan akurasi klasifikasi.</p>
<p><strong>HASIL &amp; INTERPRETASI</strong></p>
<p>Hasil evaluasi menunjukkan bahwa model Decision Tree mampu menghasilkan tingkat akurasi yang tinggi pada data hasil diskretisasi Equal Frequency. Berdasarkan confusion matrix dan classification report, sebagian besar data uji berhasil diklasifikasikan dengan benar, dan hanya terdapat sedikit kesalahan prediksi. Visualisasi pohon keputusan juga memperlihatkan jalur pemisahan antar kelas yang cukup jelas berdasarkan fitur-fitur diskrit yang digunakan. Hal ini menandakan bahwa Decision Tree merupakan algoritma yang cukup fleksibel dalam menghadapi data kategorikal, dan diskretisasi Equal Frequency tidak terlalu mengurangi kualitas informasi penting dari fitur aslinya. Berikut implementasi bentuk code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data (ulang supaya fair)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Buat dan latih model Decision Tree ===</span>
<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># === Prediksi ===</span>
<span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Evaluasi ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Evaluasi Decision Tree Setelah Diskritisasi Equal Frequency ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>

<span class="c1"># Visualisasi pohon keputusan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span>
               <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
               <span class="n">class_names</span><span class="o">=</span><span class="n">dt_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
               <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi Pohon Keputusan (Decision Tree) - Diskritisasi Equal Frequency&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Evaluasi Decision Tree Setelah Diskritisasi Equal Frequency ===

Confusion Matrix:
[[10  0  0]
 [ 0  8  1]
 [ 0  1 10]]

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        10
  versicolor       0.89      0.89      0.89         9
   virginica       0.91      0.91      0.91        11

    accuracy                           0.93        30
   macro avg       0.93      0.93      0.93        30
weighted avg       0.93      0.93      0.93        30

Akurasi: 0.9333333333333333
</pre></div>
</div>
<img alt="_images/e20f9d092a88f6c69dfecbc7145b7d760f89e98b63cacc8b50ba29a398802eb4.png" src="_images/e20f9d092a88f6c69dfecbc7145b7d760f89e98b63cacc8b50ba29a398802eb4.png" />
</div>
</div>
</section>
<section id="id8">
<h2><strong>Hasil Akurasi Keduanya</strong><a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>Hasil perbandingan menunjukkan bahwa kedua model mampu mencapai akurasi yang tinggi, dengan Decision Tree sedikit lebih unggul dibandingkan Naive Bayes dalam konteks data yang telah didiskretisasi. Grafik batang perbandingan memperlihatkan perbedaan akurasi yang tidak terlalu besar, namun Decision Tree cenderung lebih fleksibel dalam menangani pola klasifikasi kompleks karena strukturnya yang eksplisit dan cabang logika yang dalam. Sebaliknya, Naive Bayes tetap mempertahankan performa yang baik meskipun pendekatannya lebih sederhana dan mengasumsikan independensi antar fitur. Secara keseluruhan, kedua model tetap efektif digunakan setelah diskretisasi, tergantung pada kebutuhan interpretabilitas dan efisiensi komputasi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hitung akurasi masing-masing model</span>
<span class="n">akk_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">akk_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>


<span class="c1"># === Cetak akurasi kedua model ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Perbandingan Akurasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Naive Bayes     : </span><span class="si">{</span><span class="n">akk_nb</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Decision Tree   : </span><span class="si">{</span><span class="n">akk_dt</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Buat DataFrame untuk visualisasi</span>
<span class="n">accuracy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Model&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">akk_nb</span><span class="p">,</span> <span class="n">akk_dt</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">:</span> <span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">:</span> <span class="s1">&#39;lightgreen&#39;</span><span class="p">}</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">accuracy_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi Model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Perbandingan Akurasi ===
Akurasi Naive Bayes     : 0.9333
Akurasi Decision Tree   : 0.9333
</pre></div>
</div>
<img alt="_images/216a14c986f577be626d5e2c68d6170ee4067fa8f6630073fd3e6162e6311be6.png" src="_images/216a14c986f577be626d5e2c68d6170ee4067fa8f6630073fd3e6162e6311be6.png" />
</div>
</div>
</section>
<section id="hasil-perbandingan-akhir">
<h2>✅<strong>Hasil Perbandingan Akhir</strong><a class="headerlink" href="#hasil-perbandingan-akhir" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Klasifikasi 1</p></li>
</ol>
<ul class="simple">
<li><p>Naive Bayes : 1.0</p></li>
<li><p>DecisionTree : 1.0</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Klasifikasi 2</p></li>
</ol>
<ul class="simple">
<li><p>Naive Bayes : 0.96</p></li>
<li><p>DecisionTree : 0.96</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Klasifikasi 3</p></li>
</ol>
<ul class="simple">
<li><p>Naive bayes : 0.9</p></li>
<li><p>DecisionTree : 0.96</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Klasifikasi 4</p></li>
</ol>
<ul class="simple">
<li><p>Naive Bayes : 0.93</p></li>
<li><p>DecisionTree : 0.93</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Diskirminasi menggunakan K-means</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengertian-diskritisasi-discretization"><strong>Pengertian Diskritisasi (Discretization)</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-1"><strong>Klasifikasi 1</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengumpulkan-data-iris"><strong>Mengumpulkan data Iris</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-naive-bayes"><strong>Klasifikasi menggunakan naive bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-decisiontree"><strong>Klasifikasi menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-prediksi-keduanya"><strong>Hasil Prediksi keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-2"><strong>Klasifikasi 2</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Mengumpulkan data Iris</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dan-cluster-data-menjadi-4-kelas"><strong>Diskritisasi data dan Cluster data menjadi 4 kelas</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>Klasifikasi menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>Klasifikasi Menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akurasi-keduanya"><strong>Hasil Akurasi Keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-3"><strong>Klasifikasi 3</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dengan-equal-width-binning"><strong>Diskritisasi Data dengan Equal Width-Binning</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-equal-width-binning-untuk-data-iris-sebagai-berikut"><strong>Langkah-langkah Equal Width-Binning untuk data Iris Sebagai berikut:</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Klasifikasi Menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Klasifikasi Menggunakan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Hasil Akurasi Keduanya</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-4"><strong>Klasifikasi 4</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-dengan-equal-frequency"><strong>Klasifikasi data dengan Equal Frequency</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-equal-frequency-untuk-data-iris-sebagai-berikut"><strong>Langkah-langkah Equal Frequency untuk data Iris sebagai berikut:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Klasifikasi Menggunakan Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifisikas-dengan-decisiontree"><strong>Klasifisikas dengan DecisionTree</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Hasil Akurasi Keduanya</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-perbandingan-akhir">✅<strong>Hasil Perbandingan Akhir</strong></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>